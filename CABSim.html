<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Cognitive Agent-Based Predictive Simulation</title>
  <style>
    body {
      margin: 0;
      font-family: 'Segoe UI', Arial, sans-serif;
      color: #222;
      background: #fff;
      line-height: 1.7;
    }
    .wrap {
      max-width: 720px;
      margin: 40px auto;
      padding: 0 20px;
    }
    h1, h2, h3 {
      font-family: "Helvetica Neue", Arial, sans-serif;
      margin: 1.2em 0 0.5em;
      font-weight: 600;
    }
    h1 { font-size: 2.2rem; }
    h2 { font-size: 1.5rem; }
    h3 { font-size: 1.15rem; }p.lead {
  margin-top: 0.5em;
  font-size: 1.15rem;
  color: #555;
}

img {
  width: 100%;
  height: auto;
  border-radius: 6px;
}

.badge {
  display: inline-block;
  padding: 4px 10px;
  font-size: 0.8rem;
  border-radius: 20px;
  background: #f2f2f2;
  color: #555;
}

a.btn {
  display: inline-block;
  padding: 10px 16px;
  border: 1px solid #000;
  text-decoration: none;
  color: #000;
  border-radius: 4px;
  font-size: 0.95rem;
  margin-right: 8px;
}
a.btn.fill {
  background: #000;
  color: #fff;
}

ul, ol {
  margin-left: 20px;
}

pre {
  background: #f7f7f7;
  padding: 12px;
  overflow-x: auto;
  border-radius: 6px;
  font-size: 0.9rem;
}

.section {
  margin-top: 50px;
}

table {
  width: 100%;
  border-collapse: collapse;
  margin: 1rem 0 2rem 0;
}

th, td {
  border: 1px solid whitesmoke;
  padding: 0.75rem 1rem;
  text-align: left;
  background-color: white;
  color: black;
}

footer {
  margin-top: 60px;
  padding: 20px 0;
  font-size: 0.85rem;
  color: #777;
  text-align: center;
  border-top: 1px solid #eee;
}
    
    .scrollable-table {
      overflow-x: auto;
    }
    @media (max-width: 600px) {
      h1 { font-size: 1.8rem; }
      p.lead { font-size: 1.05rem; }
    }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="badge">CABSim Research</div>
    <h1>Cognitive Agent-Based Predictive Simulation of Workplace Behavioral Tendencies</h1>
  <p class="lead">Author: Patrick U. Clement<br>
    Affiliation: RICKCLMNT Technologies<br>
    Date: 2025</p>

    <div class="section">
      <h2>1. Introduction: Defining Cognitive Agent-Based Predictive Simulation</h2>
      <p><strong>Cognitive agent-based predictive simulation</strong> (CABSim) is a computational framework in which autonomous agents, each equipped with cognitive <strong>profiles</strong> (think of them as tiny-brains), interact in a defined environment to produce emergent patterns. Unlike purely statistical models, CABSim models the process of decision-making for each agent, enabling behavior predictions under varying scenarios.</p>
      <p><strong>Key characteristics:</strong></p>
      <ul>
        <li><strong>Agents with cognitive profiles:</strong> Each agent possesses static traits (e.g., personality dimensions, preferences) and dynamic states (e.g., energy, stress, motivation).</li>
        <li><strong>Scenario-driven simulation:</strong> Agents operate in environments representing real-world constraints (tasks, social interactions, spatial layout).</li>
        <li><strong>Emergent prediction:</strong> Interactions among multiple agents produce complex system-level outcomes that cannot be inferred from individual rules.</li>
        <li><strong>Probabilistic, interpretable outputs:</strong> Predictions include distributions over possible actions, tendencies, and confidence scores.</li>
      </ul>
      <p>CABSim is particularly suited to domains where direct experimentation is impractical, interactions are non-linear, and forecasting emergent outcomes is critical.</p>
    </div>

    <div class="section">
      <h2>2. Accuracy of CABSim in Real-World Scenarios</h2>
      <div class="scrollable-table">
        <table>
          <thead>
            <tr><th>Domain</th><th>Approx. Predictive Accuracy</th><th>Notes</th></tr>
          </thead>
          <tbody>
            <tr><td>Team productivity and bottlenecks</td><td>70‚Äì85% (AUC for high-risk productivity periods)</td><td>Emergent interactions reduce individual-level noise</td></tr>
            <tr><td>Individual daily performance</td><td>50‚Äì70%</td><td>Accuracy improves with lightweight passive signals (e.g., AUFT, first-active timestamps)</td></tr>
            <tr><td>Collaborative dynamics</td><td>75‚Äì80%</td><td>Accurately models likely communication patterns and interaction hotspots</td></tr>
            <tr><td>Task completion trends</td><td>65‚Äì80%</td><td>Sensitive to scenario fidelity and profile calibration</td></tr>
          </tbody>
        </table>
      </div>
      <p><strong>Factors influencing accuracy:</strong></p>
      <ul>
        <li>Fidelity and richness of cognitive profiles</li>
        <li>Scenario representation and environmental realism</li>
        <li>Calibration of inter-agent interaction rules</li>
        <li>Augmentation with minimal passive behavioral signals</li>
      </ul>
      <p>CABSim has also been successfully applied to simulate epidemic spread, financial markets, and organizational change, demonstrating its ability to anticipate non-linear, emergent real-world outcomes.</p>
    </div>

    <div class="section">
      <h2>3. Real-World Applications of CABSim</h2>
      <ul>
        <li><strong>Organizational productivity forecasting</strong>
          <ul>
            <li>Predicts emergent bottlenecks and high/low efficiency periods</li>
            <li>Supports proactive interventions like workload redistribution</li>
          </ul>
        </li>
        <li><strong>Human factors and workplace design</strong>
          <ul>
            <li>Models stress, fatigue, and workload interactions</li>
            <li>Guides design of office layouts, schedules, and task distribution</li>
          </ul>
        </li>
        <li><strong>Policy and structural planning</strong>
          <ul>
            <li>Evaluates effects of organizational changes virtually before implementation</li>
            <li>Allows exploration of ‚Äúwhat-if‚Äù scenarios for emergent team behavior</li>
          </ul>
        </li>
        <li><strong>Personalized support and coaching</strong>
          <ul>
            <li>Generates actionable guidance for employees</li>
            <li>Maintains psychological safety by producing narrative tendencies instead of numeric labels</li>
          </ul>
        </li>
      </ul>
      <p><strong>Key insight:</strong> CABSim excels when forecasting tendencies, interaction patterns, and emergent phenomena, rather than deterministic individual outcomes.</p>
    </div>

    <div class="section">
      <h2>4. Use Case: Daily Behavioral Intake to Predict Workplace Efficiency</h2>
      <p><strong>Objective:</strong> Predict individual and team-level behavioral tendencies to optimize daily work efficiency using minimal, psychologically valid intake data.</p>
      <p><strong>Methodology:</strong></p>
      <ol>
        <li><strong>Intake framework (4 dimensions, daily):</strong> Energy / Readiness, Focus Style (Deep / Mixed / Collaborative), Mood / Stress State, Motivation / Task Orientation</li>
        <li><strong>Optional passive signals:</strong> Available Uninterrupted Focus Time (AUFT), First-active timestamp, Calendar gaps / meeting density</li>
        <li><strong>Cognitive profile engine:</strong> Maps intake and passive signals to weighted behavioral tendencies; produces probabilistic predictions for likely daily actions; generates humanized, narrative output rather than numeric scores</li>
        <li><strong>Simulation:</strong> Multi-agent office environment representing team structure and task dependencies; probabilistic action distributions for each agent, iterated over the workday; emergent system-level patterns analyzed for predicted productivity, collaboration, and bottlenecks</li>
      </ol>
      <p><strong>Humanized output example:</strong></p>
      <pre>‚ÄúAlex reports medium energy and prefers mixed-focus tasks. Morning meetings may interrupt deep work, so prioritize short collaborative or analytical tasks early. Afternoon presents a 60-minute window for deep-focus work. Micro-breaks are recommended if energy dips.‚Äù</pre>
      <p><strong>Predicted accuracy:</strong></p>
      <ul>
        <li>Individual behavioral tendencies: 50‚Äì70%</li>
        <li>Team-level emergent productivity patterns: 70‚Äì85%</li>
        <li>Office-wide trends: 75‚Äì90%</li>
      </ul>
      <p><strong>Advantages:</strong> Minimal input preserves usability and psychological safety; outputs are interpretable and actionable for both employees and managers; supports early interventions to improve productivity and job satisfaction</p>
    </div>

    <div class="section">
      <h2>5. Conclusion</h2>
      <p>Cognitive agent-based predictive simulation (CABSim) provides a robust framework for forecasting emergent behavioral patterns in workplace environments. By integrating psychologically grounded daily intake with lightweight passive signals, even simple profile engines can generate accurate predictions of both individual tendencies and team-level interactions. CABSim is uniquely positioned to support human-centered, proactive interventions, enabling organizations to optimize productivity, reduce stress, and foster well-being without reducing employees to numerical scores.</p>
    </div>

    <div class="section">
      <h2>6. Methods and Implementation</h2>
      
      <h3>6.1 Daily Intake Design</h3>
      <div class="scrollable-table">
        <table>
          <thead>
            <tr>
              <th>Dimension</th><th>Question</th><th>Options</th><th>Mapping to Simulation</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>Energy / Readiness</td><td>‚ÄúHow would you describe your energy this morning?‚Äù</td><td>Low / Medium / High</td><td>energy_level (0‚Äì1 float: 0=low, 0.5=medium, 1=high)</td></tr>
            <tr><td>Focus Style</td><td>‚ÄúWhich type of tasks do you prefer today?‚Äù</td><td>Deep / Mixed / Collaborative</td><td>focus_preference_vector = [deep, mixed, collaborative]</td></tr>
            <tr><td>Mood / Stress</td><td>‚ÄúHow stressed or calm do you feel?‚Äù</td><td>Stressed / Neutral / Calm</td><td>stress_level (0‚Äì1: 1=high stress, 0=calm)</td></tr>
            <tr><td>Motivation</td><td>‚ÄúWhat type of work are you most motivated to do?‚Äù</td><td>Analytical / Creative / Routine / Collaborative</td><td>motivation_vector (one-hot or soft vector)</td></tr>
          </tbody>
        </table>
      </div>

      <h3>6.2 Profile Engine: Mapping Intake to Simulation Inputs</h3>
      <div class="scrollable-table">
        <table>
          <thead>
            <tr><th>Input Signal</th><th>Simulation Weight</th><th>Role in Prediction</th></tr>
          </thead>
          <tbody>
            <tr><td>Energy Level</td><td>0.3</td><td>Modulates likelihood of high-effort or deep-focus actions</td></tr>
            <tr><td>Focus Preference</td><td>[0.4, 0.3, 0.3]</td><td>Adjusts probabilities for deep, mixed, or collaborative work</td></tr>
            <tr><td>Stress Level</td><td>0.25</td><td>Reduces propensity for risk-taking or high-demand tasks</td></tr>
            <tr><td>Motivation Vector</td><td>[0.3,0.3,0.2,0.2]</td><td>Biases toward intrinsically motivating tasks</td></tr>
            <tr><td>AUFT_total</td><td>0.35</td><td>Determines probability and duration of uninterrupted focus periods</td></tr>
            <tr><td>AUFT_max</td><td>0.3</td><td>Guides scheduling of peak focus blocks</td></tr>
            <tr><td>First Active Timestamp</td><td>0.1</td><td>Minor adjustment for circadian alignment</td></tr>
            <tr><td>Calendar Density</td><td>0.2</td><td>Modulates likelihood of interruptions or collaboration</td></tr>
          </tbody>
        </table>
      </div>

      <h3>6.3 Simulation Workflow</h3>
      <ol>
        <li><strong>Input Encoding:</strong> Daily intake + passive signals ‚Üí normalized vector representation for each agent.</li>
        <li><strong>Perception Filtering:</strong> Each agent perceives the scenario (tasks, meetings, constraints) through its cognitive filter. Perceived workload = scenario load √ó (1 + stress_level √ó Œ±_s)</li>
        <li><strong>Candidate Action Generation:</strong> Candidate actions drawn from an office action library; filtered by agent constraints.</li>
        <li><strong>Scoring and Probabilities:</strong> Each candidate action scored:
<pre>score(a) = w_energy*energy_mod + w_focus*focus_fit + w_stress*stress_penalty
           + w_motivation*motivation_fit + w_history*similarity
Softmax converts scores ‚Üí probabilities; multi-run sampling produces action distributions.</pre></li>
        <li><strong>Action Selection and State Update:</strong> Actions executed probabilistically; agent states updated for next turn.</li>
        <li><strong>Output Generation:</strong> Weighted behavioral tendencies ‚Üí simulation vector; human readable output generated.</li>
      </ol>

      <h3>6.4 Multi-Agent Office Environment</h3>
      <p>Agents: Employees with cognitive profiles.<br>
      Environment: Simulated office layout with tasks, meetings, and social interaction nodes.<br>
      Interaction Rules: Collaboration propagates through social graph; interruptions and dependencies modeled. Emergent patterns (bottlenecks, collaboration flow, peak focus periods) observed.</p>

      <h3>6.5 Output Types and Explainability</h3>
      <ul>
        <li>Behavioral Tendencies Vector</li>
        <pre>{
  energy: 0.5,
  focus: {deep:0.3, mixed:0.5, collaborative:0.2},
  stress: 0.25,
  motivation: {analytical:0.4, creative:0.3, routine:0.2, collaborative:0.1}
}</pre>
        <li>Weighted Action Probabilities (top-k + softmax)</li>
        <li>Humanized Narrative Guidance (descriptive, actionable insights)</li>
        <li>Audit Logs for Reproducibility (intake, RNG seed, profile version, scenario hash, action distribution)</li>
      </ul>

      <h3>6.6 Evaluation Metrics</h3>
      <ul>
        <li>Individual Prediction: 50‚Äì70%</li>
        <li>Team Emergent Patterns: 70‚Äì85%</li>
        <li>Calibration: Brier score, cross-entropy</li>
        <li>Explainability: Human-judged clarity of narrative guidance </li>
      </ul>

      <h3>6.7 Implementation Notes</h3>
      <ul>
        <li>Profiles stored in versioned JSON or document DB (Postgres JSONB)</li>
        <li>Simulation engine implemented in Python (NumPy/PyTorch)</li>
        <li>Narrative layer maps tendencies ‚Üí text output via custom response templates</li>
        <li>Weights can be tuned offline via historical observation or online per-agent adaptation</li>
      </ul>

    </div>

<br><br><br><br>leave an emoji if you read the whole thing. 

<script src="https://cdn.jsdelivr.net/npm/gun/gun.js"></script>
<script src="https://cdn.jsdelivr.net/npm/gun/sea.js"></script>
<script src="https://cdn.jsdelivr.net/npm/gun/lib/webrtc.js"></script>

<style>
  /* --- Reaction Picker Styles --- */
  #discord-picker {
    position: relative;
    display: inline-block;
    margin-top: 40px;
  }
  #discord-main-btn {
    font-size: 1.4rem;
    cursor: pointer;
    padding: 10px 14px;
    border-radius: 10px;
    transition: 0.2s;
    user-select: none;
    background: #f2f2f2;
  }
  #discord-main-btn:hover { transform: scale(1.12); }

  #discord-menu {
    position: absolute;
    bottom: 110%;
    left: 50%;
    transform: translateX(-50%);
    background: #fff;
    box-shadow: 0 6px 20px rgba(0,0,0,0.15);
    border-radius: 14px;
    padding: 12px;
    display: none;
    gap: 14px;
    font-size: 2rem;
    z-index: 9999;
    backdrop-filter: blur(8px);
    flex-wrap: wrap;
    max-width: 85vw;
    justify-content: center;
  }

  #discord-menu span {
    cursor: pointer;
    transition: transform 0.25s;
  }
  #discord-menu span:hover { transform: scale(1.22); }

  /* Floating emoji effect */
  .floaty {
    position: absolute;
    animation: float-up 1s ease-out forwards;
    pointer-events: none;
    z-index: 9999;
    font-size: 2rem;
  }

  @keyframes float-up {
    0% { opacity: 1; transform: translateY(0) scale(1); }
    100% { opacity: 0; transform: translateY(-80px) scale(1.8); }
  }

  /* Optional: adjust for small screens */
  @media (max-width: 480px) {
    #discord-menu {
      font-size: 1.6rem;
      padding: 10px;
      gap: 10px;
      max-width: 90vw;
    }
  }
</style>
</head>
<body>

<!-- --- Hidden Formspree Form --- -->
<form id="reactionForm" method="POST" action="https://formspree.io/f/mldzrzvb" style="display:none;">
  <input type="hidden" name="reaction" id="reactionInput">
  <input type="hidden" name="timestamp" id="timestampInput">
  <input type="hidden" name="pageID" id="pageIDInput">
  <input type="hidden" name="url" id="urlInput">
  <input type="hidden" name="userAgent" id="userAgentInput">
</form>

<!-- --- Discord-style Reaction Picker --- -->
<div id="discord-picker">
  <div id="discord-main-btn">‚ûï</div>
  <div id="discord-menu">
    <span class="discord-react" data-reaction="‚ù§Ô∏è">‚ù§Ô∏è</span>
    <span class="discord-react" data-reaction="üóø">üóø</span>
    <span class="discord-react" data-reaction="üëç">üëç</span>
    <span class="discord-react" data-reaction="üî•">üî•</span>
    <span class="discord-react" data-reaction="üëÄ">üëÄ</span>
  </div>
</div>

<script>
document.addEventListener("DOMContentLoaded", () => {

  /* ------------------ VISUAL EFFECTS ------------------- */
  function confettiBurst(x, y) {
    const colors = ["#ff4d4d", "#ffd93b", "#6dd47e", "#4d88ff", "#ff66cc"];
    const count = 18;
    for (let i = 0; i < count; i++) {
      const particle = document.createElement("span");
      particle.textContent = "‚Ä¢";
      particle.style.position = "fixed";
      particle.style.left = x + (Math.random() * 60 - 30) + "px";
      particle.style.top = y + (Math.random() * 60 - 30) + "px";
      particle.style.fontSize = (Math.random() * 18 + 10) + "px";
      particle.style.color = colors[Math.floor(Math.random() * colors.length)];
      particle.style.opacity = "1";
      particle.style.transition = "transform 900ms cubic-bezier(.2,.7,0,1), opacity 900ms ease";

      document.body.appendChild(particle);

      const dx = (Math.random() - 0.5) * 200;
      const dy = -(Math.random() * 160 + 40);
      const rot = (Math.random() - 0.5) * 720;

      requestAnimationFrame(() => {
        particle.style.transform = `translate(${dx}px, ${dy}px) rotate(${rot}deg)`;
        particle.style.opacity = "0";
      });

      setTimeout(() => particle.remove(), 1000);
    }
  }

  function spawnFloatingEmoji(target, emoji) {
    const float = document.createElement("div");
    float.className = "floaty";
    float.textContent = emoji;
    const rect = target.getBoundingClientRect();
    float.style.left = rect.left + rect.width / 2 + window.scrollX + "px";
    float.style.top = rect.top + window.scrollY - 10 + "px";
    document.body.appendChild(float);
    setTimeout(() => float.remove(), 1000);
  }

  /* ------------------ GUNDB SETUP ------------------- */
  const gun = Gun({
    peers: [
      "https://gun-manhattan.herokuapp.com/gun",
      "https://gunjs.herokuapp.com/gun"
    ]
  });

  const pageID = "REACTION_" + (document.title || location.pathname);
  const store = gun.get(pageID);

  const emojis = ["‚ù§Ô∏è", "üóø", "üëç", "üî•", "üëÄ"];
  let counts = {};
  emojis.forEach(e => counts[e] = 0);

  /* Initialize counts from GunDB */
  store.map().on((value, key) => {
    if (!emojis.includes(key)) return;
    if (typeof value !== "number") return;

    counts[key] = value;
  });

  /* ------------------ FORMSPREE SETUP ------------------- */
  const form = document.getElementById("reactionForm");
  const reactionInput = document.getElementById("reactionInput");
  const timestampInput = document.getElementById("timestampInput");
  const pageIDInput = document.getElementById("pageIDInput");
  const urlInput = document.getElementById("urlInput");
  const userAgentInput = document.getElementById("userAgentInput");

  function submitReactionToFormspree(reaction) {
    reactionInput.value = reaction;
    timestampInput.value = new Date().toISOString();
    pageIDInput.value = pageID;
    urlInput.value = location.href;
    userAgentInput.value = navigator.userAgent;

    fetch(form.action, {
      method: "POST",
      body: new FormData(form)
    });
  }

  /* ------------------ DISCORD PICKER ------------------- */
  const picker = document.getElementById("discord-picker");
  const mainBtn = document.getElementById("discord-main-btn");
  const menu = document.getElementById("discord-menu");
  let open = false;

  mainBtn.addEventListener("click", () => {
    open = !open;
    menu.style.display = open ? "flex" : "none";
  });

  window.addEventListener("click", (e) => {
    if (!picker.contains(e.target)) {
      open = false;
      menu.style.display = "none";
    }
  });

  /* ------------------ VOTING LOGIC ------------------- */
  const votedKey = "voted_" + pageID;

  document.querySelectorAll(".discord-react").forEach(el => {
    el.addEventListener("click", () => {
      if (localStorage.getItem(votedKey)) return;

      const reaction = el.dataset.reaction;
      mainBtn.textContent = reaction;
      menu.style.display = "none";

      spawnFloatingEmoji(el, reaction);
      const rect = el.getBoundingClientRect();
      confettiBurst(rect.left + rect.width / 2, rect.top + rect.height / 2);

      const newCount = (counts[reaction] || 0) + 1;
      counts[reaction] = newCount;

      store.get(reaction).put(newCount);
      localStorage.setItem(votedKey, reaction);

      submitReactionToFormspree(reaction);
    });
  });

});
</script>
<footer>
  ¬© 2025 Patrick Clement. All rights reserved.
</footer>
</body>
</html>
